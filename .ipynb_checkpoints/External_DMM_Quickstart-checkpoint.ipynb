{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c01e6a6-9c77-473d-a1f5-d7e2f427df76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample Muliclass Model for External Domino Model Monitoring\n",
    "\n",
    "Example notebook to set up external Domino Model Monitoring:\n",
    "- Models hosted outside of Domino \n",
    "- Models scores using batch inference through Domino Jobs\n",
    "\n",
    "## Background\n",
    "The setup process is a bit different for external models being monitored with Domino Model Monitoring.\n",
    "\n",
    "(1) The model does not need to be trained in Domino- it can be an existing model trained elsewhere.\n",
    "\n",
    "(2) It does not matter where the external model is hosted. It could be on an edge device, on-prem, in your cloud hosting service, or hosted in Domino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d1b6d-ecce-4c7b-8281-9a71a3495707",
   "metadata": {},
   "source": [
    "### Register a Monitoring Data Source\n",
    "\n",
    "Domino requires an external data source to register an external model.\n",
    "\n",
    "The external data source stores the:\n",
    "\n",
    "(1) Training Dataset\n",
    "\n",
    "(2) Inference data & model predictions\n",
    "\n",
    "(3) Ground truth labels (optional)\n",
    "\n",
    "One datasource can be used for multiple DMM models. The same datasource can also be used for both ground truth labels for integrated models and data used for external models.\n",
    "\n",
    "The Domino Model Monitoring data sources are registered independently of the data sources used in Domino Workbench. Model monitoring can read in data from multiple cloud data sources or on-prem data sources. A list of available data sources is here:\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/8c7833/connect-a-data-source/\n",
    "\n",
    "You can register your DMM datasource through the DMM UI or using DMM's API (see example API call below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffd2be1-4a18-420e-945d-d319442a5547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4eb36939ce2a8d52164052acd3f4a5dd45498d5554721f677764bdb2852f7ecc\n",
      "None\n",
      "b'{\"errors\": [\"None for not nullable\", \"None is not of type \\'string\\'\", \"None for not nullable\", \"None is not of type \\'string\\'\"]}'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# API Reference: https://docs.dominodatalab.com/en/latest/api_guide/f31cde/model-monitoring-api-reference/#_datasource\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['DOMINO_USER_API_KEY']\n",
    "print(API_key)\n",
    "# UPDATE: (2) Your organizations's Domino url\n",
    "your_domino_url = 'prod-field.cs.domino.tech'\n",
    "\n",
    "# UPDATE: (3) Your new DMM datasource name\n",
    "datasource_name = 'GSK_DataSource'\n",
    "\n",
    "# UPDATE: (4) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "datasource_type = \"s3\"\n",
    "S3_Bucket_Name = \"uday-samala-dmm-test-bucket\"\n",
    "S3_Region = \"us-west-2\"\n",
    "AWS_Access_Key = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_Secret_Key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "print(AWS_Secret_Key)\n",
    "datasource_url = \"https://{}/model-monitor/v2/api/datasource\".format(your_domino_url)\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "data_source_request = {\n",
    "    \"name\": datasource_name,\n",
    "    \"type\": datasource_type,\n",
    "    \"config\" : {\n",
    "        \"bucket\": S3_Bucket_Name,\n",
    "        \"region\": S3_Region,\n",
    "        \"instance_role\" : False,\n",
    "        \"access_key\": AWS_Access_Key,\n",
    "        \"secret_key\": AWS_Secret_Key\n",
    "    }\n",
    "}\n",
    "# format(datasource_name, datasource_type, S3_Bucket_Name, S3_Region, AWS_Access_Key, AWS_Secret_Key)\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", datasource_url, headers=headers, data = json.dumps(data_source_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2db7f-89b7-4646-92d7-6aae3bf69315",
   "metadata": {},
   "source": [
    "### Register Your External Model\n",
    "\n",
    "Once you have a data source registered:\n",
    "\n",
    "(1) Upload the training dataset used for your model to that datasource, and note the path to your training dataset. DMM will need this to initiate the model.\n",
    "\n",
    "(2) Prepare your model config file. In the UI, the config json looks like the example below.\n",
    "\n",
    "It contains 3 components:\n",
    "\n",
    "(A) **variables**: A list of variable names, data types, and variable types for each column that you want to monitor. This can include the target variable if you'd like to monitor drift in your model's predictions.\n",
    "\n",
    "(B) **datasetDetails**: The location of your training dataset that you just uploaded into the DMM datasource\n",
    "\n",
    "(C) **modelMetadata**: The name and description of your model to render in Domino Model Monitoring\n",
    "\n",
    "Like with DMM Data Sources, models can be created in the UI or via APIs.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal.length\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal.length\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal.width\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal.width\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"prediction\",\n",
    "            \"name\": \"variety\"\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": \"iris.csv\",\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": \"iris.csv\",\n",
    "            \"fileFormat\": \"csv\"\n",
    "        },\n",
    "        \"datasourceName\": \"dmm-shared-bucket\",\n",
    "        \"datasourceType\": \"s3\"\n",
    "    },\n",
    "    \"modelMetadata\": {\n",
    "        \"name\": \"iris_model\",\n",
    "        \"modelType\": \"classification\",\n",
    "        \"version\": \"1.01\",\n",
    "        \"description\": \"classification_iris_model\",\n",
    "        \"author\": \"John Doe\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Example to register a model via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76e734ab-55b4-4136-94ac-b959465c3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\": \"65bc2fab54ac3acc8cb49726\", \"createdAt\": 1706831787, \"updatedAt\": 1706831787, \"name\": \"Example External Model\", \"description\": \"classification_iris_model\", \"modelType\": \"classification\", \"author\": \"John Doe\", \"version\": \"1.01\", \"userId\": \"4b684539-9bd4-46d4-bb64-60c8094ccb15\", \"isDeleted\": false, \"ingestionStatus\": \"created\", \"registrationStatus\": \"created\", \"sourceType\": \"standalone\", \"visibility\": \"public\", \"collaborators\": []}'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# API Reference: https://docs.dominodatalab.com/en/latest/user_guide/a94c1c/model-monitoring-apis/#_model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (3) Your DMM datasource name\n",
    "datasource_name = 'se-demo-bucket'\n",
    "\n",
    "# UPDATE: (4) Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# UPDATE: (5) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "training_dataset_name = \"iris_train_data.csv\"\n",
    "training_dataset_path = \"iris_train_data.csv\"\n",
    "training_dataset_fileFormat = \"csv\"\n",
    "\n",
    "datasource_url = \"https://{}/model-monitor/v2/api/model\".format(your_domino_url)\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "# Update each variable name, varibleType and valueType for your model:\n",
    "\n",
    "model_register_request = {\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal length (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal length (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal width (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal width (cm)\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"prediction\",\n",
    "            \"name\": \"variety\"\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": training_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": training_dataset_path,\n",
    "            \"fileFormat\": training_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    },\n",
    "    \"modelMetadata\": {\n",
    "        \"name\": \"Example External Model\",\n",
    "        \"modelType\": \"classification\",\n",
    "        \"version\": \"1.01\",\n",
    "        \"description\": \"classification_iris_model\",\n",
    "        \"author\": \"John Doe\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", datasource_url, headers=headers, data = json.dumps(model_register_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2909a-85cc-4c80-9db3-28a77867e22b",
   "metadata": {},
   "source": [
    "### Register Prediction Data\n",
    "\n",
    "Since this is an external model, Domino does not automatically capture prediction data.\n",
    "\n",
    "Prediction data will need to be collected in a DMM Datasource, then periodically ingested into your monitored model. You could do this manually via the API, but it is generally automated via API calls to DMM.\n",
    "\n",
    "You could append prediction data to a single file in your monitoring data source, then have Doino ingest the prediction data on a schedule.\n",
    "\n",
    "Alternatively, you can upload individual files with your prediction data to your monitoring data source, then call DMM's API to update the path to the file with the latest prediction data. This could be easily done with a scheduled Domino Job.\n",
    "\n",
    "Below is an example for the second approach, updating the file and calling DMM's API.\n",
    "\n",
    "Notes:\n",
    "- Only register a column name once. If a column name is passed to DMM a second time, it will throw an error. For example, the example below adds a new column called \"id\" that identifies each request, so that we can later pair up requests with ground truth labels. Only add this column name the first time you upload prediction data to your registered model - for any subsequent uploads only update the dataset details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "854c970b-34b5-4747-8d10-a982f80a0f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# API Reference: https://docs.dominodatalab.com/en/latest/user_guide/a94c1c/model-monitoring-apis/#_model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your Model Monitoring Model ID\n",
    "model_id='65bc2e5f198fe4d19631c582'\n",
    "\n",
    "# UPDATE: (3) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (4) Your DMM datasource name\n",
    "datasource_name = 'se-demo-bucket'\n",
    "\n",
    "# UPDATE: (5) Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# UPDATE: (6) Your RowID Name (Optional, for model quality monitoring. Do this only once.)\n",
    "Prediction_ID_name = 'id'\n",
    "\n",
    "# UPDATE: (7) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "prediction_dataset_name = \"iris_score_data.csv\"\n",
    "prediction_dataset_path = \"iris_score_data.csv\"\n",
    "prediction_dataset_fileFormat = \"csv\"\n",
    "\n",
    "prediction_data_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/prediction\".format(your_domino_url, model_id)\n",
    "\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "# Update each variable name, varibleType and valueType for your model:\n",
    "\n",
    "prediction_registration_request = {\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"string\",\n",
    "            \"variableType\": \"row_identifier\",\n",
    "            \"name\": Prediction_ID_name\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": prediction_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": prediction_dataset_path,\n",
    "            \"fileFormat\": prediction_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", prediction_data_url, headers=headers, data = json.dumps(prediction_registration_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a23c65-10c7-4217-80ab-1848f7a50b8a",
   "metadata": {},
   "source": [
    "### Ingest Ground Truth Dataset\n",
    "\n",
    "Typically for this step you would fetch actual ground truth data (the actual outcomes from what your model predicted on), \n",
    "join the actual outcomes with your prediction data, and upload into a datasource attached to model monitoring for Model Quality \n",
    "analysis.\n",
    "\n",
    "However, for purposes of creating a quick demo, we'll make up some fake ground truth data using the model predictions captured with Domino's\n",
    "data capture client. These predictions are stored in an automatically-generated Domino Dataset called \"prediction_data\"\n",
    "\n",
    "Once Data has ingested (roughly one hour), a \"prediction_data\" Domino Dataset will be added to the Project.\n",
    "\n",
    "1) Navigate to the Domino Dataset Folder on the left (back from /mnt/ , then \"data/prediction_data/...\")\n",
    "Copy the path to read in your registered model predictions.\n",
    "\n",
    "2) Join the Predictions to make your ground truth dataset, shuffle some labels to simulate classification errors, and save the ground truth csv\n",
    "\n",
    "3) Upload the csv to the s3 bucket attached as a Domino Model Monitoring Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17981520-45e2-4c06-9b06-6088bffeb897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>variety</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>__domino_timestamp</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-01-23 23:53:57.398343+00:00</td>\n",
       "      <td>2024-01-23T23:53:57.403167+00:00</td>\n",
       "      <td>69f2291e-e15d-4372-aebe-302edf53f476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-01-23 23:53:57.398343+00:00</td>\n",
       "      <td>2024-01-23T23:53:57.403685+00:00</td>\n",
       "      <td>130b85c0-91b8-4d79-b530-baf31cba5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2024-01-23 23:53:57.398343+00:00</td>\n",
       "      <td>2024-01-23T23:53:57.403968+00:00</td>\n",
       "      <td>1d41236d-c595-478b-b937-bbf451b4eb98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2024-01-23 23:53:57.398343+00:00</td>\n",
       "      <td>2024-01-23T23:53:57.404184+00:00</td>\n",
       "      <td>42f5c408-66dc-45f8-9db1-2d6c74f6438e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2024-01-23 23:53:57.398343+00:00</td>\n",
       "      <td>2024-01-23T23:53:57.404386+00:00</td>\n",
       "      <td>ca1712ba-9053-4cb8-9aa2-b57267273b44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal length (cm)  petal width (cm)  sepal length (cm)  sepal width (cm)  \\\n",
       "0                1.1               0.1                4.3               3.0   \n",
       "1                1.2               0.2                5.8               4.0   \n",
       "2                1.5               0.4                5.7               4.4   \n",
       "3                5.7               2.5                6.7               3.3   \n",
       "4                5.2               2.3                6.7               3.0   \n",
       "\n",
       "     variety                        timestamp  \\\n",
       "0     setosa 2024-01-23 23:53:57.398343+00:00   \n",
       "1     setosa 2024-01-23 23:53:57.398343+00:00   \n",
       "2     setosa 2024-01-23 23:53:57.398343+00:00   \n",
       "3  virginica 2024-01-23 23:53:57.398343+00:00   \n",
       "4  virginica 2024-01-23 23:53:57.398343+00:00   \n",
       "\n",
       "                 __domino_timestamp                              event_id  \n",
       "0  2024-01-23T23:53:57.403167+00:00  69f2291e-e15d-4372-aebe-302edf53f476  \n",
       "1  2024-01-23T23:53:57.403685+00:00  130b85c0-91b8-4d79-b530-baf31cba5860  \n",
       "2  2024-01-23T23:53:57.403968+00:00  1d41236d-c595-478b-b937-bbf451b4eb98  \n",
       "3  2024-01-23T23:53:57.404184+00:00  42f5c408-66dc-45f8-9db1-2d6c74f6438e  \n",
       "4  2024-01-23T23:53:57.404386+00:00  ca1712ba-9053-4cb8-9aa2-b57267273b44  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36478b4f-53de-4a11-879e-b7a82875a892",
   "metadata": {},
   "source": [
    "The Ground Truth dataset needs 2 columns: \n",
    "\n",
    "1) The existing event ID column from the model predictions.\n",
    "   \n",
    "    This column has the join keys for joing ground truth lables to your model's predictions\n",
    "\n",
    "3) Your new column containing ground truth labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0abbad2-3785-4cc8-b10c-608bc82ecfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_id = predictions['event_id']\n",
    "iris_ground_truth = predictions['variety']\n",
    "\n",
    "# Create a new dataframe\n",
    "ground_truth = pd.DataFrame(columns=['event_id', 'iris_ground_truth'])\n",
    "ground_truth['event_id'] = event_id\n",
    "ground_truth['iris_ground_truth'] = iris_ground_truth\n",
    "\n",
    "# These row labels help find some diferent iris types in our initial scoring data\n",
    "end_index = predictions.shape[0]\n",
    "mid_index = int(round(predictions.shape[0] / 2, 0))\n",
    "\n",
    "# Simulate some classifcation errors. This makes our confusion matrix interesting.\n",
    "ground_truth.iloc[0, 1] = 'virginica'\n",
    "ground_truth.iloc[1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index-1, 1] = 'versicolor'\n",
    "ground_truth.iloc[mid_index, 1] = 'virginica'\n",
    "ground_truth.iloc[end_index-2, 1] = 'setosa'\n",
    "ground_truth.iloc[end_index-1, 1] = 'setosa'\n",
    "\n",
    "# Save this example ground truth csv to your file to your Project files for reference.\n",
    "\n",
    "date = datetime.datetime.today()\n",
    "month = date.month\n",
    "day = date.day\n",
    "year = date.year\n",
    "\n",
    "date = str(datetime.datetime.today()).split()[0]\n",
    "\n",
    "ground_truth.to_csv('data/iris_ground_truth_{}_{}_{}.csv'.format(month, day, year), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e75973-c2f9-429e-aa4e-b8b1c029aaa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering iris_ground_truth_1_25_2024.csv From S3 Bucket in DMM\n",
      "b'[\"Dataset already registered with the model.\"]'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    " \n",
    "# UPDATE: (1) The name of your monitoring data source in Domino Model Monitoring\n",
    "data_source = 'se-demo-bucket'\n",
    "\n",
    "# UPDATE: (2) Your Model Monitoring Model ID (NOT Model API model ID)\n",
    "model_id='65b0525c54ac3acc8cb495d1'\n",
    "\n",
    "# UPDATE: (3) Your Domino API key\n",
    "API_key = os.environ['MY_API_KEY']\n",
    " \n",
    "# UPDATE: (4) The name of the file uploaded to s3 above\n",
    "gt_file_name = \"iris_ground_truth_{}_{}_{}.csv\".format(month, day, year)\n",
    "\n",
    "# UPDATE: (5) Ground Truth column name\n",
    "GT_column_name = 'iris_ground_truth'\n",
    "\n",
    "# UPDATE: (6) Your original target column name\n",
    "target_column_name = 'variety'\n",
    "\n",
    "# UPDATE: (7) Your organizations's Domino url\n",
    "your_domino_url = 'demo2.dominodatalab.com'\n",
    "\n",
    "# UPDATE: (8) Your DataSource Type\n",
    "datasource_type = \"s3\"\n",
    "\n",
    "ground_truth_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/ground_truth\".format(your_domino_url, model_id)\n",
    "\n",
    "print('Registering {} From S3 Bucket in DMM'.format(gt_file_name))\n",
    " \n",
    "# create GT payload    \n",
    " \n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    " \n",
    "ground_truth_payload = \"\"\"\n",
    "{{\n",
    "    \"variables\": [{{\n",
    "    \n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"ground_truth\",\n",
    "            \"name\": \"{2}\", \n",
    "            \"forPredictionOutput\": \"{3}\"\n",
    "        \n",
    "    }}],\n",
    "    \"datasetDetails\": {{\n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"{4}\"\n",
    "        }}\n",
    "}}\n",
    "\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name, datasource_type)\n",
    " \n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", ground_truth_url, headers=headers, data = ground_truth_payload)\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc660f-f094-4b83-bc2a-935b835e9c24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next Steps\n",
    "\n",
    "Going forward, Domino will automatically capture all prediction data going across your Model API. It will ingest these predictions for Drift detection once per day. You can set a schedule to determine when this ingest happens.\n",
    "\n",
    "To periodically upload ground truth labels, repeat the previous step, but without the “variables” in the ground truth payload (this only needs to be done once). As new ground truth labels are added, point Domino to the path to the new labels in the monitoring data source by pinging the same Model Monitoring API:\n",
    "\n",
    "ground_truth_payload = \"\"\"\n",
    "\n",
    "{{\n",
    "\n",
    "       \"datasetDetails\": {{\n",
    "        \n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"s3\"\n",
    "        }}\n",
    "}}\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cd486-42bb-48e7-85e5-2d4ed3056f18",
   "metadata": {},
   "source": [
    "### Automation with Domino Jobs\n",
    "To simulate Domino Model Monitoring over time, you can try out running the following two scripts as scheduled Domino Jobs:\n",
    "\n",
    "**(1) daily_scoring.py**\n",
    "\n",
    "Daily scoring simulates a daily batch scoring script. Data is read in, sent to the Domino Model API, and predictions are returned.\n",
    "Domino's Prediction Capture Client captures this scoring data, and every 24 hours, it gets ingested into the Drift Monitoring dashboard.\n",
    "\n",
    "**(2) daily_ground_truth.py**\n",
    "\n",
    "Daily ground truth simulates uploading actual outcomes after the predictions have been made. A scheduled Domino Job writes the latest ground truth labels to an s3 bucket, then calls the Domino Model Monitoring API with the path to the file with the latest ground truth labels.\n",
    "\n",
    "If you schedule these two jobs, be sure that ground truth runs after the predictions!"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
