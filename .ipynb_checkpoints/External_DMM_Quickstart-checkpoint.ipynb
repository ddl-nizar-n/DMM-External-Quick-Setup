{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c01e6a6-9c77-473d-a1f5-d7e2f427df76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample Muliclass Model for External Domino Model Monitoring\n",
    "\n",
    "Example notebook to set up external Domino Model Monitoring:\n",
    "- Models hosted outside of Domino \n",
    "- Models scores using batch inference through Domino Jobs\n",
    "\n",
    "## Background\n",
    "The setup process for external models being monitored with Domino Model Monitoring listed below.\n",
    "\n",
    "(1) The model does not need to be trained in Domino- it can be an existing model trained elsewhere.\n",
    "\n",
    "(2) It does not matter where the external model is hosted. It could be on an edge device, on-prem, in your cloud hosting service, or hosted in Domino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d1b6d-ecce-4c7b-8281-9a71a3495707",
   "metadata": {},
   "source": [
    "### Register a Monitoring Data Source\n",
    "\n",
    "Domino requires an external data source to register an external model.\n",
    "\n",
    "The external data source stores the:\n",
    "\n",
    "(1) Training Dataset\n",
    "\n",
    "(2) Inference data & model predictions\n",
    "\n",
    "(3) Ground truth labels (optional)\n",
    "\n",
    "One datasource can be used for multiple DMM models. The same datasource can also be used for both ground truth labels for integrated models and data used for external models.\n",
    "\n",
    "The Domino Model Monitoring data sources are registered independently of the data sources used in Domino Workbench. Model monitoring can read in data from multiple cloud data sources or on-prem data sources. A list of available data sources is here:\n",
    "https://docs.dominodatalab.com/en/latest/user_guide/8c7833/connect-a-data-source/\n",
    "\n",
    "You can register your DMM datasource through the DMM UI or using DMM's API (see example API call below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ffd2be1-4a18-420e-945d-d319442a5547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Datasource with name GSK_DataSource and type s3 is already registered.'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# API Reference: https://docs.dominodatalab.com/en/latest/api_guide/f31cde/model-monitoring-api-reference/#_datasource\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['DOMINO_USER_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your organizations's Domino url\n",
    "your_domino_url = 'prod-field.cs.domino.tech'\n",
    "\n",
    "# UPDATE: (3) Your new DMM datasource name\n",
    "datasource_name = 'GSK_DataSource'\n",
    "\n",
    "# UPDATE: (4) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "datasource_type = \"s3\"\n",
    "S3_Bucket_Name = \"uday-samala-dmm-test-bucket\"\n",
    "S3_Region = \"us-west-2\"\n",
    "AWS_Access_Key = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_Secret_Key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    " \n",
    "datasource_url = \"https://{}/model-monitor/v2/api/datasource\".format(your_domino_url)\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "data_source_request = {\n",
    "    \"name\": datasource_name,\n",
    "    \"type\": datasource_type,\n",
    "    \"config\" : {\n",
    "        \"bucket\": S3_Bucket_Name,\n",
    "        \"region\": S3_Region,\n",
    "        \"instance_role\" : False,\n",
    "        \"access_key\": AWS_Access_Key,\n",
    "        \"secret_key\": AWS_Secret_Key\n",
    "    }\n",
    "}\n",
    "# format(datasource_name, datasource_type, S3_Bucket_Name, S3_Region, AWS_Access_Key, AWS_Secret_Key)\n",
    "\n",
    "# Make api call\n",
    "datasource_response = requests.request(\"PUT\", datasource_url, headers=headers, data = json.dumps(data_source_request))\n",
    " \n",
    "# Print response\n",
    "print(datasource_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2db7f-89b7-4646-92d7-6aae3bf69315",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Register Your External Model\n",
    "\n",
    "Once you have a data source registered:\n",
    "\n",
    "(1) Upload the training dataset used for your model to that datasource, and note the path to your training dataset. DMM will need this to initiate the model.\n",
    "\n",
    "(2) Prepare your model config file. In the UI, the config json looks like the example below.\n",
    "\n",
    "It contains 3 components:\n",
    "\n",
    "(A) **variables**: A list of variable names, data types, and variable types for each column that you want to monitor. This can include the target variable if you'd like to monitor drift in your model's predictions.\n",
    "\n",
    "(B) **datasetDetails**: The location of your training dataset that you just uploaded into the DMM datasource\n",
    "\n",
    "(C) **modelMetadata**: The name and description of your model to render in Domino Model Monitoring\n",
    "\n",
    "Like with DMM Data Sources, models can be created in the UI or via APIs.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal.length\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal.length\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"petal.width\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"name\": \"sepal.width\"\n",
    "        },\n",
    "        {\n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"prediction\",\n",
    "            \"name\": \"variety\"\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": \"iris.csv\",\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": \"iris.csv\",\n",
    "            \"fileFormat\": \"csv\"\n",
    "        },\n",
    "        \"datasourceName\": \"dmm-shared-bucket\",\n",
    "        \"datasourceType\": \"s3\"\n",
    "    },\n",
    "    \"modelMetadata\": {\n",
    "        \"name\": \"iris_model\",\n",
    "        \"modelType\": \"classification\",\n",
    "        \"version\": \"1.01\",\n",
    "        \"description\": \"classification_iris_model\",\n",
    "        \"author\": \"John Doe\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Example to register a model via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e734ab-55b4-4136-94ac-b959465c3e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\": \"65ca754a69dd9289b62c0c32\", \"createdAt\": 1707767114, \"updatedAt\": 1707767114, \"name\": \"gsk-customer-churn\", \"description\": \"Classification model to predict customer churn\", \"modelType\": \"classification\", \"author\": \"Uday Samala\", \"version\": \"1.0\", \"userId\": \"0c3b0ed2-0255-449d-ac59-28d6d585f2d2\", \"isDeleted\": false, \"ingestionStatus\": \"created\", \"registrationStatus\": \"created\", \"sourceType\": \"standalone\", \"visibility\": \"public\", \"collaborators\": []}'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# API Reference: https://docs.dominodatalab.com/en/latest/user_guide/a94c1c/model-monitoring-apis/#_model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['DOMINO_USER_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your organizations's Domino url\n",
    "your_domino_url = 'prod-field.cs.domino.tech'\n",
    "\n",
    "# UPDATE: (3) Your DMM datasource name\n",
    "datasource_name = 'GSK_DataSource'\n",
    "\n",
    "# UPDATE: (4) Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# UPDATE: (5) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "training_dataset_name = \"ChurnTrainingDataPP.csv\"\n",
    "training_dataset_path = \"ChurnTrainingDataPP.csv\"\n",
    "training_dataset_fileFormat = \"csv\"\n",
    "\n",
    "datasource_url = \"https://{}/model-monitor/v2/api/model\".format(your_domino_url)\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "# Update each variable name, varibleType and valueType for your model:\n",
    "\n",
    "model_register_request = {\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"name\": \"custid\",\n",
    "            \"valueType\": \"string\",\n",
    "            \"variableType\": \"row_identifier\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dropperc\",\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"featureImportance\": 0.7\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"mins\",\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"featureImportance\": 0.9\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"consecmonths\",\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"featureImportance\": 0.1\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"income\",\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"featureImportance\": 0.3\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"age\",\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"feature\",\n",
    "            \"featureImportance\": 0.5\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"churn_Y\",\n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"prediction\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"predictionProbability\",\n",
    "            \"valueType\": \"numerical\",\n",
    "            \"variableType\": \"prediction_probability\",\n",
    "            \"forPredictionOutput\": \"churn_Y\"\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": training_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": training_dataset_path,\n",
    "            \"fileFormat\": training_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    },\n",
    "    \"modelMetadata\": {\n",
    "        \"name\": \"gsk-customer-churn\",\n",
    "        \"modelType\": \"classification\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"description\": \"Classification model to predict customer churn\",\n",
    "        \"author\": \"Uday Samala\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make api call\n",
    "model_response = requests.request(\"PUT\", datasource_url, headers=headers, data = json.dumps(model_register_request))\n",
    " \n",
    "# Print response\n",
    "print(model_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2909a-85cc-4c80-9db3-28a77867e22b",
   "metadata": {},
   "source": [
    "### Register Prediction Data\n",
    "\n",
    "Since this is an external model, Domino does not automatically capture prediction data.\n",
    "\n",
    "Prediction data will need to be collected in a DMM Datasource, then periodically ingested into your monitored model. You could do this manually via the API, but it is generally automated via API calls to DMM.\n",
    "\n",
    "You could append prediction data to a single file in your monitoring data source, then have Doino ingest the prediction data on a schedule.\n",
    "\n",
    "Alternatively, you can upload individual files with your prediction data to your monitoring data source, then call DMM's API to update the path to the file with the latest prediction data. This could be easily done with a scheduled Domino Job.\n",
    "\n",
    "Below is an example for the second approach, updating the file and calling DMM's API.\n",
    "\n",
    "Notes:\n",
    "- Only register a column name once. If a column name is passed to DMM a second time, it will throw an error. For example, the example below adds a new column called \"id\" that identifies each request, so that we can later pair up requests with ground truth labels. Only add this column name the first time you upload prediction data to your registered model - for any subsequent uploads only update the dataset details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854c970b-34b5-4747-8d10-a982f80a0f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# API Reference: https://docs.dominodatalab.com/en/latest/user_guide/a94c1c/model-monitoring-apis/#_model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['DOMINO_USER_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your Model Monitoring Model ID\n",
    "model_id='65ca754a69dd9289b62c0c32'\n",
    "\n",
    "# UPDATE: (3) Your organizations's Domino url\n",
    "your_domino_url = 'prod-field.cs.domino.tech'\n",
    "\n",
    "# UPDATE: (4) Your DMM datasource name\n",
    "datasource_name = 'GSK_DataSource'\n",
    "\n",
    "# UPDATE: (5) Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# UPDATE: (6) Your RowID Name (Optional, for model quality monitoring. Do this only once.)\n",
    "Prediction_ID_name = 'custid'\n",
    "\n",
    "# UPDATE: (7) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "prediction_dataset_name = \"inputs_and_preds_2021-09-16.csv\"\n",
    "prediction_dataset_path = \"inputs_and_preds_2021-09-16.csv\"\n",
    "prediction_dataset_fileFormat = \"csv\"\n",
    "\n",
    "prediction_data_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/prediction\".format(your_domino_url, model_id)\n",
    "\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "# Update each variable name, varibleType and valueType for your model:\n",
    "\n",
    "prediction_registration_request = {\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": prediction_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": prediction_dataset_path,\n",
    "            \"fileFormat\": prediction_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# Make api call\n",
    "prediction_response = requests.request(\"PUT\", prediction_data_url, headers=headers, data = json.dumps(prediction_registration_request))\n",
    " \n",
    "# Print response\n",
    "print(prediction_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a23c65-10c7-4217-80ab-1848f7a50b8a",
   "metadata": {},
   "source": [
    "### Ingest Ground Truth Dataset\n",
    "\n",
    "Typically for this step you would fetch actual ground truth data (the actual outcomes from what your model predicted on), \n",
    "join the actual outcomes with your prediction data, and upload into a datasource attached to model monitoring for Model Quality \n",
    "analysis.\n",
    "\n",
    "However, for purposes of creating a quick demo, we'll make up some fake ground truth data using the model predictions captured with Domino's\n",
    "data capture client. These predictions are stored in an automatically-generated Domino Dataset called \"prediction_data\"\n",
    "\n",
    "Once Data has ingested (roughly one hour), a \"prediction_data\" Domino Dataset will be added to the Project.\n",
    "\n",
    "1) Navigate to the Domino Dataset Folder on the left (back from /mnt/ , then \"data/prediction_data/...\")\n",
    "Copy the path to read in your registered model predictions.\n",
    "\n",
    "2) Join the Predictions to make your ground truth dataset, shuffle some labels to simulate classification errors, and save the ground truth csv\n",
    "\n",
    "3) Upload the csv to the s3 bucket attached as a Domino Model Monitoring Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17981520-45e2-4c06-9b06-6088bffeb897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# API Reference: https://docs.dominodatalab.com/en/latest/user_guide/a94c1c/model-monitoring-apis/#_model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# UPDATE: (1) Your Domino API key\n",
    "API_key = os.environ['DOMINO_USER_API_KEY']\n",
    "\n",
    "# UPDATE: (2) Your Model Monitoring Model ID\n",
    "model_id='65ca754a69dd9289b62c0c32'\n",
    "\n",
    "# UPDATE: (3) Your organizations's Domino url\n",
    "your_domino_url = 'prod-field.cs.domino.tech'\n",
    "\n",
    "# UPDATE: (4) Your DMM datasource name\n",
    "datasource_name = 'GSK_DataSource'\n",
    "\n",
    "# UPDATE: (5) Your DMM datasource type\n",
    "datasource_type = 's3'\n",
    "\n",
    "# UPDATE: (6) Your RowID Name (Optional, for model quality monitoring. Do this only once.)\n",
    "groudtruth_ID_name = 'custid'\n",
    "\n",
    "# UPDATE: (7) DMM Datasource Type & Attributes. These credential will be different for each datasource.\n",
    "groudtruth_dataset_name = \"ground_truth_2021-09-16.csv\"\n",
    "groudtruth_dataset_path = \"ground_truth_2021-09-16.csv\"\n",
    "groudtruth_dataset_fileFormat = \"csv\"\n",
    "\n",
    "groudtruth_data_url = \"https://{}/model-monitor/v2/api/model/{}/register-dataset/ground_truth\".format(your_domino_url, model_id)\n",
    "\n",
    "\n",
    "# Set up call headers\n",
    "headers = {\n",
    "           'X-Domino-Api-Key': API_key,\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "\n",
    "# Update each variable name, varibleType and valueType for your model:\n",
    "\n",
    "groudtruth_registration_request = {\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"valueType\": \"categorical\",\n",
    "            \"variableType\": \"ground_truth\",\n",
    "            \"name\": \"y_gt\",\n",
    "            \"forPredictionOutput\": \"churn_Y\"\n",
    "        }\n",
    "    ],\n",
    "    \"datasetDetails\": {\n",
    "        \"name\": groudtruth_dataset_name,\n",
    "        \"datasetType\": \"file\",\n",
    "        \"datasetConfig\": {\n",
    "            \"path\": groudtruth_dataset_path,\n",
    "            \"fileFormat\": groudtruth_dataset_fileFormat\n",
    "        },\n",
    "        \"datasourceName\": datasource_name,\n",
    "        \"datasourceType\": datasource_type\n",
    "    }\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "# Make api call\n",
    "ground_truth_response = requests.request(\"PUT\", groudtruth_data_url, headers=headers, data = json.dumps(groudtruth_registration_request))\n",
    " \n",
    "# Print response\n",
    "print(ground_truth_response.text.encode('utf8'))\n",
    " \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36478b4f-53de-4a11-879e-b7a82875a892",
   "metadata": {},
   "source": [
    "The Ground Truth dataset needs 2 columns: \n",
    "\n",
    "1) The existing event ID column from the model predictions.\n",
    "   \n",
    "    This column has the join keys for joing ground truth lables to your model's predictions\n",
    "\n",
    "3) Your new column containing ground truth labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0abbad2-3785-4cc8-b10c-608bc82ecfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e75973-c2f9-429e-aa4e-b8b1c029aaa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering iris_ground_truth_1_25_2024.csv From S3 Bucket in DMM\n",
      "b'[\"Dataset already registered with the model.\"]'\n",
      "DONE!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fafc660f-f094-4b83-bc2a-935b835e9c24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next Steps\n",
    "\n",
    "\n",
    "To periodically upload ground truth labels, repeat the previous step, but without the “variables” in the ground truth payload (this only needs to be done once). As new ground truth labels are added, point Domino to the path to the new labels in the monitoring data source by pinging the same Model Monitoring API:\n",
    "\n",
    "ground_truth_payload = \"\"\"\n",
    "\n",
    "{{\n",
    "\n",
    "       \"datasetDetails\": {{\n",
    "        \n",
    "            \"name\": \"{0}\",\n",
    "            \"datasetType\": \"file\",\n",
    "            \"datasetConfig\": {{\n",
    "                \"path\": \"{0}\",\n",
    "                \"fileFormat\": \"csv\"\n",
    "            }},\n",
    "            \"datasourceName\": \"{1}\",\n",
    "            \"datasourceType\": \"s3\"\n",
    "        }}\n",
    "}}\"\"\".format(gt_file_name, data_source, GT_column_name, target_column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cd486-42bb-48e7-85e5-2d4ed3056f18",
   "metadata": {},
   "source": [
    "### Automation with Domino Jobs\n",
    "To simulate Domino Model Monitoring over time, you can try out running the following two scripts as scheduled Domino Jobs:\n",
    "\n",
    "**(1) daily_scoring.py**\n",
    "\n",
    "Daily scoring simulates a daily batch scoring script. Data is read in, sent to the Domino Model API, and predictions are returned.\n",
    "Domino's Prediction Capture Client captures this scoring data, and every 24 hours, it gets ingested into the Drift Monitoring dashboard.\n",
    "\n",
    "**(2) daily_ground_truth.py**\n",
    "\n",
    "Daily ground truth simulates uploading actual outcomes after the predictions have been made. A scheduled Domino Job writes the latest ground truth labels to an s3 bucket, then calls the Domino Model Monitoring API with the path to the file with the latest ground truth labels.\n",
    "\n",
    "If you schedule these two jobs, be sure that ground truth runs after the predictions!"
   ]
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
